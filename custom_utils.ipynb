{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "path = 'ClimbingHoldDetection-15/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ClimbingHoldDetection-15/train/_annotations.coco.json') as f:\n",
    "    file = json.loads(f.read())\n",
    "    images = file['images']\n",
    "    annotations = file['annotations']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'image_id': 0,\n",
       " 'category_id': 5,\n",
       " 'bbox': [202, 104, 137.5, 70.5],\n",
       " 'area': 9693.75,\n",
       " 'segmentation': [],\n",
       " 'iscrowd': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'license': 1,\n",
       " 'file_name': '20231009_133118_jpg.rf.a4403489a7a5e6fb3150293fb413dd6f.jpg',\n",
       " 'height': 640,\n",
       " 'width': 640,\n",
       " 'date_captured': '2023-11-06T01:50:53+00:00'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bbox(image, bbox_coord):\n",
    "    x, y, w, h = [int(b) for b in bbox_coord]\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def parse_annotations(annotations):\n",
    "    img_id_to_annotations = {}\n",
    "\n",
    "    for a in annotations:\n",
    "        if a['image_id'] in img_id_to_annotations:\n",
    "            img_id_to_annotations[a['image_id']].append(a['id'])\n",
    "        else:\n",
    "            img_id_to_annotations[a['image_id']] = [a['id']]\n",
    "\n",
    "    return img_id_to_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id_to_annotations = parse_annotations(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def getBoudingBoxForImage(imageId, img_id_to_annotations, annotations, images, path = 'ClimbingHoldDetection-15/train', saving_dir=None):\n",
    "    annotation_ids = img_id_to_annotations[imageId]\n",
    "    img_path =  os.path.join(path, images[imageId]['file_name'])\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "\n",
    "    for a_id in annotation_ids:\n",
    "        extracted_img = extract_bbox(image, annotations[a_id]['bbox'])\n",
    "        if saving_dir:\n",
    "            cv2.imwrite(os.path.join(saving_dir, f\"{imageId:05d}_{a_id:05d}.png\"), extracted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAllImages(interval, img_id_to_annotations, annotations, images, path = 'ClimbingHoldDetection-15/train', saving_dir=None):\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(interval):\n",
    "        getBoudingBoxForImage(i, img_id_to_annotations, annotations, images, saving_dir=\"extractedLabeledDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/383 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 382/383 [00:07<00:00, 51.29it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "382",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6623811bfc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextractAllImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m383\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id_to_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"extractedLabeledDataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-efab54719e30>\u001b[0m in \u001b[0;36mextractAllImages\u001b[0;34m(interval, img_id_to_annotations, annotations, images, path, saving_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mgetBoudingBoxForImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id_to_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"extractedLabeledDataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ee9e06e16cc7>\u001b[0m in \u001b[0;36mgetBoudingBoxForImage\u001b[0;34m(imageId, img_id_to_annotations, annotations, images, path, saving_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetBoudingBoxForImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id_to_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ClimbingHoldDetection-15/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mannotation_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_id_to_annotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimageId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimageId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 382"
     ]
    }
   ],
   "source": [
    "extractAllImages(range(0,382), img_id_to_annotations, annotations, images, saving_dir=\"extractedLabeledDataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Crimp\n",
    "# 2: Jug\n",
    "# 3: Pinch\n",
    "# 4: Pocket\n",
    "# 5: Sloper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations, img_dir, transform=None):\n",
    "        # self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.annotations = annotations\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imageId = self.annotations[idx]['image_id']\n",
    "        img_path = os.path.join(self.img_dir, f\"{imageId:05d}_{idx:05d}.png\")\n",
    "        \n",
    "        image = read_image(img_path)\n",
    "        label = self.annotations[idx]['category_id']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_data(img_dir, annotations, batch_size=2, shuffle=False):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64))\n",
    "    ])\n",
    "    trainDataset = CustomImageDataset(annotations, img_dir, transform=transform)\n",
    "    train_dataloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    train_images, train_labels = next(iter(train_dataloader))\n",
    "    return train_dataloader\n",
    "\n",
    "# img_dir = \"extractedLabeledDataset\"\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((64,64))\n",
    "# ])\n",
    "# trainDataset = CustomImageDataset(annotations, img_dir, transform=transform)\n",
    "\n",
    "# train_dataloader = DataLoader(trainDataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# train_images, train_labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations():\n",
    "    return annotations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
