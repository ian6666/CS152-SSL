{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms,models,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # Freeze the parameters of the model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "    return model.to(device), loss_fn, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_summary\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: torch-summary\n",
      "Successfully installed torch-summary-1.4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurie/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/laurie/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/laurie/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 29.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 112, 112]        (9,408)\n",
      "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        (128)\n",
      "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-5                        [-1, 64, 56, 56]          --\n",
      "|    └─BasicBlock: 2-1                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          (36,864)\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          (128)\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          (36,864)\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          (128)\n",
      "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
      "|    └─BasicBlock: 2-2                   [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 64, 56, 56]          (36,864)\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 64, 56, 56]          (128)\n",
      "|    |    └─ReLU: 3-9                    [-1, 64, 56, 56]          --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 64, 56, 56]          (36,864)\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 64, 56, 56]          (128)\n",
      "|    |    └─ReLU: 3-12                   [-1, 64, 56, 56]          --\n",
      "├─Sequential: 1-6                        [-1, 128, 28, 28]         --\n",
      "|    └─BasicBlock: 2-3                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 128, 28, 28]         (73,728)\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 128, 28, 28]         (256)\n",
      "|    |    └─ReLU: 3-15                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 28, 28]         (147,456)\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 128, 28, 28]         (256)\n",
      "|    |    └─Sequential: 3-18             [-1, 128, 28, 28]         (8,448)\n",
      "|    |    └─ReLU: 3-19                   [-1, 128, 28, 28]         --\n",
      "|    └─BasicBlock: 2-4                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 128, 28, 28]         (147,456)\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 128, 28, 28]         (256)\n",
      "|    |    └─ReLU: 3-22                   [-1, 128, 28, 28]         --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 128, 28, 28]         (147,456)\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 128, 28, 28]         (256)\n",
      "|    |    └─ReLU: 3-25                   [-1, 128, 28, 28]         --\n",
      "├─Sequential: 1-7                        [-1, 256, 14, 14]         --\n",
      "|    └─BasicBlock: 2-5                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 14, 14]         (294,912)\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 14, 14]         (512)\n",
      "|    |    └─ReLU: 3-28                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 256, 14, 14]         (589,824)\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 256, 14, 14]         (512)\n",
      "|    |    └─Sequential: 3-31             [-1, 256, 14, 14]         (33,280)\n",
      "|    |    └─ReLU: 3-32                   [-1, 256, 14, 14]         --\n",
      "|    └─BasicBlock: 2-6                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 256, 14, 14]         (589,824)\n",
      "|    |    └─BatchNorm2d: 3-34            [-1, 256, 14, 14]         (512)\n",
      "|    |    └─ReLU: 3-35                   [-1, 256, 14, 14]         --\n",
      "|    |    └─Conv2d: 3-36                 [-1, 256, 14, 14]         (589,824)\n",
      "|    |    └─BatchNorm2d: 3-37            [-1, 256, 14, 14]         (512)\n",
      "|    |    └─ReLU: 3-38                   [-1, 256, 14, 14]         --\n",
      "├─Sequential: 1-8                        [-1, 512, 7, 7]           --\n",
      "|    └─BasicBlock: 2-7                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 512, 7, 7]           (1,179,648)\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 512, 7, 7]           (1,024)\n",
      "|    |    └─ReLU: 3-41                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 512, 7, 7]           (2,359,296)\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 512, 7, 7]           (1,024)\n",
      "|    |    └─Sequential: 3-44             [-1, 512, 7, 7]           (132,096)\n",
      "|    |    └─ReLU: 3-45                   [-1, 512, 7, 7]           --\n",
      "|    └─BasicBlock: 2-8                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-46                 [-1, 512, 7, 7]           (2,359,296)\n",
      "|    |    └─BatchNorm2d: 3-47            [-1, 512, 7, 7]           (1,024)\n",
      "|    |    └─ReLU: 3-48                   [-1, 512, 7, 7]           --\n",
      "|    |    └─Conv2d: 3-49                 [-1, 512, 7, 7]           (2,359,296)\n",
      "|    |    └─BatchNorm2d: 3-50            [-1, 512, 7, 7]           (1,024)\n",
      "|    |    └─ReLU: 3-51                   [-1, 512, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --\n",
      "├─Sequential: 1-10                       [-1, 1]                   --\n",
      "|    └─Flatten: 2-9                      [-1, 512]                 --\n",
      "|    └─Linear: 2-10                      [-1, 128]                 65,664\n",
      "|    └─ReLU: 2-11                        [-1, 128]                 --\n",
      "|    └─Dropout: 2-12                     [-1, 128]                 --\n",
      "|    └─Linear: 2-13                      [-1, 1]                   129\n",
      "|    └─Sigmoid: 2-14                     [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 11,242,305\n",
      "Trainable params: 65,793\n",
      "Non-trainable params: 11,176,512\n",
      "Total mult-adds (G): 1.84\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 37.90\n",
      "Params size (MB): 42.89\n",
      "Estimated Total Size (MB): 81.36\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 112, 112]        (9,408)\n",
       "├─BatchNorm2d: 1-2                       [-1, 64, 112, 112]        (128)\n",
       "├─ReLU: 1-3                              [-1, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [-1, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [-1, 64, 56, 56]          --\n",
       "|    └─BasicBlock: 2-1                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 56, 56]          (36,864)\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 56, 56]          (128)\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 56, 56]          (36,864)\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 56, 56]          (128)\n",
       "|    |    └─ReLU: 3-6                    [-1, 64, 56, 56]          --\n",
       "|    └─BasicBlock: 2-2                   [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 64, 56, 56]          (36,864)\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 64, 56, 56]          (128)\n",
       "|    |    └─ReLU: 3-9                    [-1, 64, 56, 56]          --\n",
       "|    |    └─Conv2d: 3-10                 [-1, 64, 56, 56]          (36,864)\n",
       "|    |    └─BatchNorm2d: 3-11            [-1, 64, 56, 56]          (128)\n",
       "|    |    └─ReLU: 3-12                   [-1, 64, 56, 56]          --\n",
       "├─Sequential: 1-6                        [-1, 128, 28, 28]         --\n",
       "|    └─BasicBlock: 2-3                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 128, 28, 28]         (73,728)\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 128, 28, 28]         (256)\n",
       "|    |    └─ReLU: 3-15                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 128, 28, 28]         (147,456)\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 128, 28, 28]         (256)\n",
       "|    |    └─Sequential: 3-18             [-1, 128, 28, 28]         (8,448)\n",
       "|    |    └─ReLU: 3-19                   [-1, 128, 28, 28]         --\n",
       "|    └─BasicBlock: 2-4                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 128, 28, 28]         (147,456)\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 128, 28, 28]         (256)\n",
       "|    |    └─ReLU: 3-22                   [-1, 128, 28, 28]         --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 128, 28, 28]         (147,456)\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 128, 28, 28]         (256)\n",
       "|    |    └─ReLU: 3-25                   [-1, 128, 28, 28]         --\n",
       "├─Sequential: 1-7                        [-1, 256, 14, 14]         --\n",
       "|    └─BasicBlock: 2-5                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 256, 14, 14]         (294,912)\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 256, 14, 14]         (512)\n",
       "|    |    └─ReLU: 3-28                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 256, 14, 14]         (589,824)\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 256, 14, 14]         (512)\n",
       "|    |    └─Sequential: 3-31             [-1, 256, 14, 14]         (33,280)\n",
       "|    |    └─ReLU: 3-32                   [-1, 256, 14, 14]         --\n",
       "|    └─BasicBlock: 2-6                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-33                 [-1, 256, 14, 14]         (589,824)\n",
       "|    |    └─BatchNorm2d: 3-34            [-1, 256, 14, 14]         (512)\n",
       "|    |    └─ReLU: 3-35                   [-1, 256, 14, 14]         --\n",
       "|    |    └─Conv2d: 3-36                 [-1, 256, 14, 14]         (589,824)\n",
       "|    |    └─BatchNorm2d: 3-37            [-1, 256, 14, 14]         (512)\n",
       "|    |    └─ReLU: 3-38                   [-1, 256, 14, 14]         --\n",
       "├─Sequential: 1-8                        [-1, 512, 7, 7]           --\n",
       "|    └─BasicBlock: 2-7                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-39                 [-1, 512, 7, 7]           (1,179,648)\n",
       "|    |    └─BatchNorm2d: 3-40            [-1, 512, 7, 7]           (1,024)\n",
       "|    |    └─ReLU: 3-41                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 512, 7, 7]           (2,359,296)\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 512, 7, 7]           (1,024)\n",
       "|    |    └─Sequential: 3-44             [-1, 512, 7, 7]           (132,096)\n",
       "|    |    └─ReLU: 3-45                   [-1, 512, 7, 7]           --\n",
       "|    └─BasicBlock: 2-8                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-46                 [-1, 512, 7, 7]           (2,359,296)\n",
       "|    |    └─BatchNorm2d: 3-47            [-1, 512, 7, 7]           (1,024)\n",
       "|    |    └─ReLU: 3-48                   [-1, 512, 7, 7]           --\n",
       "|    |    └─Conv2d: 3-49                 [-1, 512, 7, 7]           (2,359,296)\n",
       "|    |    └─BatchNorm2d: 3-50            [-1, 512, 7, 7]           (1,024)\n",
       "|    |    └─ReLU: 3-51                   [-1, 512, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [-1, 512, 1, 1]           --\n",
       "├─Sequential: 1-10                       [-1, 1]                   --\n",
       "|    └─Flatten: 2-9                      [-1, 512]                 --\n",
       "|    └─Linear: 2-10                      [-1, 128]                 65,664\n",
       "|    └─ReLU: 2-11                        [-1, 128]                 --\n",
       "|    └─Dropout: 2-12                     [-1, 128]                 --\n",
       "|    └─Linear: 2-13                      [-1, 1]                   129\n",
       "|    └─Sigmoid: 2-14                     [-1, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 11,242,305\n",
       "Trainable params: 65,793\n",
       "Non-trainable params: 11,176,512\n",
       "Total mult-adds (G): 1.84\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 37.90\n",
       "Params size (MB): 42.89\n",
       "Estimated Total Size (MB): 81.36\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torch_summary\n",
    "from torchsummary import summary\n",
    "model, criterion, optimizer = get_model()\n",
    "summary(model, torch.zeros(1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, optimizer, loss_fn):\n",
    "    model.train()  # Set the model to training mode\n",
    "    prediction = model(x)\n",
    "    \n",
    "    # For multi-class classification, ensure y is in the correct shape\n",
    "    # and of a suitable dtype, like long. \n",
    "    # This might require modification depending on how your labels 'y' are provided.\n",
    "\n",
    "    batch_loss = loss_fn(prediction, y)  # CrossEntropyLoss is used for multi-class\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero the gradients before backward pass\n",
    "    batch_loss.backward()  # Compute the gradients\n",
    "    optimizer.step()  # Update parameters\n",
    "    \n",
    "    return batch_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    is_correct = (prediction > 0.5) == y\n",
    "    return is_correct.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurie/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/laurie/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from custom_utils import get_annotations\n",
    "from custom_utils import get_data\n",
    "annotations = get_annotations()\n",
    "trn_dl = get_data(\"extractedLabeledDataset\", annotations)\n",
    "model, loss_fn, optimizer = get_model(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All losses and accuracies are for each epoch\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accuracies = [], []\n",
    "\n",
    "print(\"All losses and accuracies are for each epoch\")\n",
    "for epoch in range(5):\n",
    "    train_epoch_losses, train_epoch_accuracies = [], []\n",
    "\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        try:\n",
    "            x, y = batch\n",
    "            x = x.float()  # Convert to float\n",
    "            y = y.long()   # Convert to long for classification labels\n",
    "\n",
    "            batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "            train_epoch_losses.append(batch_loss)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred at batch {ix}: {e}\")\n",
    "            continue  # Skip this batch\n",
    "\n",
    "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
    "\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        x = x.float()  # Convert to float\n",
    "        y = y.long()   # Convert to long for classification labels\n",
    "        \n",
    "\n",
    "        batch_accuracy = accuracy(x, y, model)\n",
    "        train_epoch_accuracies.append(batch_accuracy)\n",
    "\n",
    "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/5, Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.4f}\")\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    train_accuracies.append(train_epoch_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
